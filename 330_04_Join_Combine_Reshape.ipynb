{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SI 330: Data Manipulation \n",
    "## 04 - Joining, Combining, and Reshaping\n",
    "\n",
    "### Dr. Chris Teplovs, School of Information, University of Michigan\n",
    "<small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a>This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "* use pd.read_html's parameters to extract specific tables from web pages\n",
    "* create dataframes from lists and dictionaries\n",
    "* use Pandas' apply function to run a function on each row of a dataframe\n",
    "* view and set the indexes of a dataframe, including hierarchical indexes\n",
    "* use loc to explore a dataframe with hierarchical indexes\n",
    "* use stack and unstack to reshape dataframes\n",
    "* concatenate two DataFrames by columns\n",
    "* rename a dataframe's columns with a dictionary\n",
    "* use Pandas' merge functionn to join dataframes in a SQL-like way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab was inspired by https://pythonhealthcare.org/2018/04/08/32-reshaping-pandas-data-with-stack-unstack-pivot-and-melt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### IMPORTANT: Replace ```?``` in the following code with your uniqname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_UNIQNAME = '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start...\n",
    "### <font color=\"magenta\">Q1: (1 point) Please let us know what you found confusing in the last class. </font>\n",
    "We'll try to take time in the next class to review these concepts next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q1",
     "cell_type": "reflection_answer"
    }
   },
   "source": [
    "\n",
    "Replace this with your response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review from last class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from last class the ```read_html``` function, which made extracting tables from HTML pages a lot easier than using\n",
    "BeautifulSoup (in fact, it uses bs4 but hides the ugly details).  Let's warm up for today's class by extracting some information from\n",
    "a number of Wikipedia pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our top-level goal is to extract information about the _aliases_ of some Lord Of The Rings characters.  Take a look at the Wikipedia page\n",
    "for [Frodo Baggins](https://en.wikipedia.org/wiki/Frodo_Baggins) to get an idea of the sort of pages we're looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frodo_url = 'https://en.wikipedia.org/wiki/Frodo_Baggins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frodo_tables = pd.read_html(frodo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frodo_tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the page for [Legolas](https://en.wikipedia.org/wiki/Legolas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legolas_url = 'https://en.wikipedia.org/wiki/Legolas'\n",
    "legolas_tables = pd.read_html(legolas_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legolas_tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm.  That doesn't look quite right.\n",
    "\n",
    "Let's take a look at some URLs and figure out what's going on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q2: (1 point) Inspect the Frodo and Legolas pages and see if you can figure out some _attributes_ of the table we're interested in.  </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q2",
     "cell_type": "reflection_answer"
    }
   },
   "source": [
    "Describe what you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that there are some characteristics that the \"Information\" box share across pages.  We can leverage that \n",
    "information by using the ```attrs``` attribute of ```read_html```.  For example, if we wanted to extract  the element(s) that had\n",
    "an ```id``` of ```info```, we could use\n",
    "\n",
    "```pd.read_html(url,{'id':'info'})```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q3: (1 point) Fill in the following code block to extract only the \"Information\" table for the Legolas page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q3",
     "cell_type": "code_answer"
    }
   },
   "outputs": [],
   "source": [
    "a = {} # create an appropriate dictionary\n",
    "pd.read_html(legolas_url, attrs=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that, given a Wikipedia URL, will extract the contents of the Aliases component of the infobox table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aliases(url):\n",
    "    tables = pd.read_html(url, attrs={'class':'infobox'}) # extract only tables with class=infobox\n",
    "    print(url,len(tables))   # sanity check: we should have just 1 table\n",
    "    infotable = tables[0]    # pull the first table into a DataFrame\n",
    "    ret = ''                 # initialize an empty string for our return value\n",
    "    try:                     # in case the next line throws an exception\n",
    "        x = infotable.set_index(0).loc['Aliases'] # setting the index on column 0 will allow us to use .loc to look up the value of 'Aliases'\n",
    "        ret = x.values[0]\n",
    "    except:\n",
    "        ret = 'None'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aliases(legolas_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good.  It seems to work.  Now let's set up a DataFrame with a bunch of URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://en.wikipedia.org/wiki/Gimli_(Middle-earth)',\n",
    "        'https://en.wikipedia.org/wiki/Frodo_Baggins',\n",
    "        'https://en.wikipedia.org/wiki/Legolas',\n",
    "        'https://en.wikipedia.org/wiki/Bilbo_Baggins',\n",
    "        'https://en.wikipedia.org/wiki/Samwise_Gamgee',\n",
    "        'https://en.wikipedia.org/wiki/Peregrin_Took',\n",
    "        'https://en.wikipedia.org/wiki/Boromir',\n",
    "        'https://en.wikipedia.org/wiki/Galadriel',\n",
    "        'https://en.wikipedia.org/wiki/Meriadoc_Brandybuck']\n",
    "names = ['Gimli',\n",
    "         'Frodo',\n",
    "         'Legolas',\n",
    "         'Bilbo',\n",
    "         'Sam',\n",
    "         'Pippin',\n",
    "         'Boromir',\n",
    "         'Galadriel',\n",
    "         'Meriadoc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = pd.DataFrame()\n",
    "udf['name'] = names\n",
    "udf['url'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pythonic way of iterating through each of those rows would involve the use of some sort of ```for``` loop.  In pandas,\n",
    "however, as can use the ```apply``` function to process an entire column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['url'].apply(get_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the resulting Series and assign it to a new column in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['aliases'] = udf['url'].apply(get_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just put the ```udf``` DataFrame aside for now.  We'll return to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames and Exploring Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the usual libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some lists of data that we can use to construct a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Gandalf',\n",
    "         'Gimli',\n",
    "         'Frodo',\n",
    "         'Legolas',\n",
    "         'Bilbo',\n",
    "         'Sam',\n",
    "         'Pippin',\n",
    "         'Boromir',\n",
    "         'Aragorn',\n",
    "         'Galadriel',\n",
    "         'Meriadoc',\n",
    "        'Lily']\n",
    "races = ['Maia',\n",
    "         'Dwarf',\n",
    "         'Hobbit',\n",
    "         'Elf',\n",
    "         'Hobbit',\n",
    "         'Hobbit',\n",
    "         'Hobbit',\n",
    "         'Man',\n",
    "         'Man',\n",
    "         'Elf',\n",
    "         'Hobbit',\n",
    "        'Hobbit']\n",
    "magic = [10, 1, 4, 6, 4, 2, 0, 0, 2, 9, 0, np.NaN]\n",
    "aggression = [7, 10, 2, 5, 1, 6, 3, 8, 7, 2, 4, np.NaN ]\n",
    "stealth = [8, 2, 5, 10, 5, 4 ,5, 3, 9, 10, 6, np.NaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few different ways to construct a DataFrame.  We can either use an empty constructor and assign Series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\"> Q4: (2 points) Construct a dataframe with 5 columns (names, races, magic, aggression, and stealth) using the lists above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q4",
     "cell_type": "rcode_answer"
    }
   },
   "outputs": [],
   "source": [
    "df = # Insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have set things up with a dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name': names,'race':races,'magic':magic,'aggression': aggression,'stealth':stealth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the index on the resulting DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the index to something more useful than the default RangeIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nameindexed = df.set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we take a look at the results, we see that we have a pandas Index instead of a RangeIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nameindexed.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nameindexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the name Series as the index allows us to do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nameindexed.loc['Aragorn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recall the Hierarchical indexing from the readings.  We can pass a list of column names to set_index to create a Hierarchical Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed = df.set_index(['race','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow us to get a DataFrame that matches a value on the outer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed.loc['Hobbit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the index on a Series to match the outer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed['magic'].loc['Hobbit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or both indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed['magic'].loc['Hobbit','Frodo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just the inner index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_racename_indexed['magic'].loc[:,'Frodo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\"> Q5: (1 point) Using .loc find how much aggression Legalos, an Elf, has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q4",
     "cell_type": "rcode_answer"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking takes \"wide\" data and makes it \"taller\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['race']).stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call reset_index on the resulting Series, we get the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['race']).stack().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names in the above DataFrame aren't particularly helpful, so we can rename them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['race']).stack().reset_index().rename(columns = {'level_0':'ID','level_1':'variable',0:'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the opposite of stacking by using the ```unstack``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked = df.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to stack or unstack?  It depends on what sorts of analyses we want to do \"downstream\".  It's also the basis for pivoting, melting, and pivot tables, which we'll cover in the next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's say we have another CSV file that contains URLs to Wikipedia pages for some of the LOTR characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('data/lotr_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the original DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the rows are \"aligned\", so we can use the ```concat``` function to concatenate the two DataFrames.\n",
    "Note that we specify the axis to be the columns.  The default is to concatenate by rows, which isn't what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,urls],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great, and it's consistent with what we've used in previous classes.  But what happens if the \n",
    "rows in the two DataFrames don't match up?  Let's load another file that has a slightly different\n",
    "sequence of rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\"> Q6: (1 point) Construct a dataframe with lotr_wikipedia_wrong_order.csv which is in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q4",
     "cell_type": "rcode_answer"
    }
   },
   "outputs": [],
   "source": [
    "urls_wrong_order = # Insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,urls_wrong_order],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a closer look at the name and url columns.  Something's not quite right.\n",
    "\n",
    "We can work around that by using the appropriate indexing and then using the SQL-like ```merge``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order_names = urls_wrong_order.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.join(urls_wrong_order_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a few additional URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_extras = pd.read_csv(\"data/lotr_wikipedia_extras.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's use concat to add the new entries to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_complete = pd.concat([urls,urls_extras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a complete (for our purposes) list of URLs, let's use that DataFrame and our original\n",
    "one to demonstrate the different types of ```join```s.\n",
    "\n",
    "By default, ```join``` uses a left join, which means the all the values from the \"left\"\n",
    "side are used, whether or not there's a corresponding entry from the \"right\" side.  In the example \n",
    "below, note that the url value for \"Lily\" is \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"opposite\" of a left join is, perhaps unsurprisingly, a \"right\" join, in which\n",
    "all the values from the \"right\" side are used, whether or not a corresponding\n",
    "value from the \"left\" side exists. Note in the following example that \"Lily\" has\n",
    "disappeared, and Treebeard and Elrond lack information about \"race\", \"magic\", \"aggression\", and \"stealth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name',how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to \"left\" and \"right\" joins, we have \"outer\" joins, which include\n",
    "values from both the \"left\" and \"right\" DataFrames, regardless of whether\n",
    "there are corresponding values in the other DataFrame.  Note that all of \n",
    "\"Lily\", \"Treebeard\" and \"Elrond\" are present in the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are \"inner\" joins, which include only those values that exist in both the \"left\" and \"right\" DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's nice to know how a particular row got added to the resulting DataFrame.  Using ```indicator=True```\n",
    "allows us to examine this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that we used the ```merge``` function from the DataFrame and passed in the other DataFrame as an argument.\n",
    "You can also call the ```merge``` function from pandas directly and pass it the two DataFrames you are merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df,urls_complete,how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q7: (3 point) Join the ```udf``` DataFrame (that contains aliases) to the ```df``` DataFrame using an appropriate merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q4",
     "cell_type": "rcode_answer"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK\n",
    "Please remember to submit your notebook in .ipynb and .html formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
